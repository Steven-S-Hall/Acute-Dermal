{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary QSAR in Python - LabMol\n",
    "\n",
    "Script version 2 - 11/02/2019\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color='blue'> Model building with Morgan fingerprint and RF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building - Morgan_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages \n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, matthews_corrcoef, roc_curve, precision_recall_curve, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading molecules and activity (0 and 1) from SDF\n",
    "fname = \"C:/Users/steve/Documents/Datasets/dermal/Dermal_Modeling_set.sdf\"\n",
    "\n",
    "mols = []\n",
    "y = []\n",
    "for mol in Chem.SDMolSupplier(fname):\n",
    "    if mol is not None:\n",
    "        mols.append(mol)\n",
    "        y.append(mol.GetIntProp(\"Binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptors (fingerprints) and convert them into numpy array\n",
    "\n",
    "# generate binary Morgan fingerprint with radius 2\n",
    "fp = [AllChem.GetMorganFingerprintAsBitVect(m, 2,nBits=1024) for m in mols]\n",
    "\n",
    "def rdkit_numpy_convert(fp):\n",
    "    output = []\n",
    "    for f in fp:\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(f, arr)\n",
    "        output.append(arr)\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rdkit_numpy_convert(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Check the number of compounds\n",
    "len(x)\n",
    "print (type(y[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data set is balanced\n",
    "#sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed to make all further calculations reproducible\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 20% of compounds as test set\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folds for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1\n",
      "('TRAIN:', array([115, 117, 118, 119, 125, 126, 127, 128, 131, 132, 133, 134, 135,\n",
      "       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "       162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "       175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "       188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "       201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "       240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "       253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "       266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
      "       279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "       292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "       305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317,\n",
      "       318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "       331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369,\n",
      "       370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
      "       383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "       396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
      "       409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "       422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "       435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "       448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460,\n",
      "       461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "       474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "       487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499,\n",
      "       500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512,\n",
      "       513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
      "       526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
      "       539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
      "       552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590,\n",
      "       591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603,\n",
      "       604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 120,\n",
      "       121, 122, 123, 124, 129, 130], dtype=int64))\n",
      "\n",
      "Fold_2\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 120,\n",
      "       121, 122, 123, 124, 129, 130, 229, 233, 234, 237, 243, 244, 246,\n",
      "       248, 251, 252, 253, 255, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "       266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
      "       279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "       292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "       305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317,\n",
      "       318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "       331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369,\n",
      "       370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
      "       383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "       396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
      "       409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "       422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "       435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "       448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460,\n",
      "       461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "       474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "       487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499,\n",
      "       500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512,\n",
      "       513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
      "       526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
      "       539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
      "       552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590,\n",
      "       591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603,\n",
      "       604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([115, 117, 118, 119, 125, 126, 127, 128, 131, 132, 133, 134, 135,\n",
      "       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "       162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "       175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "       188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "       201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "       227, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 242, 245,\n",
      "       247, 249, 250, 254, 256, 257], dtype=int64))\n",
      "\n",
      "Fold_3\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 235, 236,\n",
      "       238, 239, 240, 241, 242, 245, 247, 249, 250, 254, 256, 257, 348,\n",
      "       350, 352, 362, 364, 368, 369, 371, 374, 375, 376, 379, 380, 381,\n",
      "       382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "       395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
      "       408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
      "       421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "       434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
      "       447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
      "       460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "       473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
      "       486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
      "       551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
      "       564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576,\n",
      "       577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
      "       590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
      "       603, 604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([229, 233, 234, 237, 243, 244, 246, 248, 251, 252, 253, 255, 258,\n",
      "       259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271,\n",
      "       272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284,\n",
      "       285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "       298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310,\n",
      "       311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "       324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "       337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 351,\n",
      "       353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367,\n",
      "       370, 372, 373, 377, 378], dtype=int64))\n",
      "\n",
      "Fold_4\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 351, 353,\n",
      "       354, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 370,\n",
      "       372, 373, 377, 378, 485, 486, 489, 490, 491, 492, 494, 495, 496,\n",
      "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
      "       551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
      "       564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576,\n",
      "       577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
      "       590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
      "       603, 604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([348, 350, 352, 362, 364, 368, 369, 371, 374, 375, 376, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "       420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "       433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "       446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "       459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471,\n",
      "       472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "       487, 488, 493, 497, 498], dtype=int64))\n",
      "\n",
      "Fold_5\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 487, 488, 493, 497, 498], dtype=int64))\n",
      "('TEST:', array([485, 486, 489, 490, 491, 492, 494, 495, 496, 499, 500, 501, 502,\n",
      "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
      "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
      "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
      "       542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554,\n",
      "       555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "       568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580,\n",
      "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
      "       594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606,\n",
      "       607, 608, 609, 610], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# print out ids of folds\n",
    "for i, (train_index, test_index) in enumerate(cv.split(x_tr, y_tr)):\n",
    "    print(\"\\nFold_\" + str(i+1))\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale X\n",
    "#This step may be crucial for certain modeling approaches lke SVM. \n",
    "#In the case of binary fingerprints it may be less useful.\n",
    "# obtain scale object which can be further applied to scale any data to fit the training set\n",
    "scale = StandardScaler().fit(x_tr)\n",
    "x_tr = scale.transform(x_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for optimal tuning parameters and build the model\n",
    "# create grid search dictionary\n",
    "param_grid = {\"max_features\": [x_tr.shape[1] // 10, x_tr.shape[1] // 7, x_tr.shape[1] // 5, x_tr.shape[1] // 3], \"n_estimators\": [100, 250, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': [102L, 146L, 204L, 341L], 'n_estimators': [100, 250, 500]}\n"
     ]
    }
   ],
   "source": [
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model building\n",
    "rf = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'max_features': [102L, 146L, 204L, 341L], 'n_estimators': [100, 250, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model building\n",
    "rf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 146L, 'n_estimators': 100}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594108019639935"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74468085, 0.73813421, 0.73977087, 0.7594108 , 0.75286416,\n",
       "       0.74959083, 0.74631751, 0.73649755, 0.74795417, 0.72667758,\n",
       "       0.72340426, 0.73486088])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_features': 102L, 'n_estimators': 100},\n",
       " {'max_features': 102L, 'n_estimators': 250},\n",
       " {'max_features': 102L, 'n_estimators': 500},\n",
       " {'max_features': 146L, 'n_estimators': 100},\n",
       " {'max_features': 146L, 'n_estimators': 250},\n",
       " {'max_features': 146L, 'n_estimators': 500},\n",
       " {'max_features': 204L, 'n_estimators': 100},\n",
       " {'max_features': 204L, 'n_estimators': 250},\n",
       " {'max_features': 204L, 'n_estimators': 500},\n",
       " {'max_features': 341L, 'n_estimators': 100},\n",
       " {'max_features': 341L, 'n_estimators': 250},\n",
       " {'max_features': 341L, 'n_estimators': 500}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/steve/rf_clf.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save model - pkl file\n",
    "tuple_objects = (rf, x_tr, y_tr)\n",
    "\n",
    "joblib.dump(rf.best_estimator_, \"C:/Users/steve/rf_clf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale descriptors of the test set compounds\n",
    "x_ts = scale.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Outcome class\n",
    "pred_rf = rf.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics - Morgan-RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate statistics for test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy = ', 0.738562091503268)\n",
      "('MCC = ', 0.476027397260274)\n",
      "('Kappa = ', 0.476027397260274)\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "accuracy = accuracy_score(y_ts, pred_rf)\n",
    "mcc = matthews_corrcoef(y_ts, pred_rf)\n",
    "kappa = cohen_kappa_score(y_ts, pred_rf)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "print(\"MCC = \", mcc)\n",
    "print(\"Kappa = \", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA estimation\n",
    "# if the model includes several ones like RF models or consensus models (or for probabilistic models)\n",
    "# we can calculate consistency of predictions amongs those models and use it for estimation of applicability domain\n",
    "#just remove the hashtag to execute\n",
    "pred_prob_rf = rf.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29, 0.71],\n",
       "       [0.17, 0.83],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.17, 0.83],\n",
       "       [0.08, 0.92],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.08, 0.92],\n",
       "       [0.02, 0.98],\n",
       "       [0.49, 0.51],\n",
       "       [0.16, 0.84],\n",
       "       [0.57, 0.43],\n",
       "       [0.81, 0.19],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.01, 0.99],\n",
       "       [0.77, 0.23],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.03, 0.97],\n",
       "       [0.84, 0.16],\n",
       "       [0.91, 0.09],\n",
       "       [0.84, 0.16],\n",
       "       [0.61, 0.39],\n",
       "       [0.22, 0.78],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.27, 0.73],\n",
       "       [0.28, 0.72],\n",
       "       [0.54, 0.46],\n",
       "       [0.38, 0.62],\n",
       "       [0.74, 0.26],\n",
       "       [0.08, 0.92],\n",
       "       [0.65, 0.35],\n",
       "       [0.12, 0.88],\n",
       "       [0.4 , 0.6 ],\n",
       "       [0.65, 0.35],\n",
       "       [0.48, 0.52],\n",
       "       [0.06, 0.94],\n",
       "       [0.73, 0.27],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.26, 0.74],\n",
       "       [0.48, 0.52],\n",
       "       [0.84, 0.16],\n",
       "       [0.32, 0.68],\n",
       "       [0.46, 0.54],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.41, 0.59],\n",
       "       [0.89, 0.11],\n",
       "       [0.32, 0.68],\n",
       "       [0.88, 0.12],\n",
       "       [0.04, 0.96],\n",
       "       [0.81, 0.19],\n",
       "       [0.79, 0.21],\n",
       "       [0.74, 0.26],\n",
       "       [0.09, 0.91],\n",
       "       [0.84, 0.16],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.18, 0.82],\n",
       "       [0.36, 0.64],\n",
       "       [0.92, 0.08],\n",
       "       [0.19, 0.81],\n",
       "       [0.01, 0.99],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.15, 0.85],\n",
       "       [0.81, 0.19],\n",
       "       [0.49, 0.51],\n",
       "       [0.06, 0.94],\n",
       "       [0.39, 0.61],\n",
       "       [0.96, 0.04],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.57, 0.43],\n",
       "       [0.14, 0.86],\n",
       "       [0.23, 0.77],\n",
       "       [0.65, 0.35],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.03, 0.97],\n",
       "       [0.44, 0.56],\n",
       "       [0.88, 0.12],\n",
       "       [0.13, 0.87],\n",
       "       [0.93, 0.07],\n",
       "       [0.41, 0.59],\n",
       "       [1.  , 0.  ],\n",
       "       [0.3 , 0.7 ],\n",
       "       [1.  , 0.  ],\n",
       "       [0.19, 0.81],\n",
       "       [0.06, 0.94],\n",
       "       [0.58, 0.42],\n",
       "       [0.16, 0.84],\n",
       "       [0.35, 0.65],\n",
       "       [0.86, 0.14],\n",
       "       [0.03, 0.97],\n",
       "       [0.86, 0.14],\n",
       "       [0.92, 0.08],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.47, 0.53],\n",
       "       [0.13, 0.87],\n",
       "       [0.69, 0.31],\n",
       "       [0.12, 0.88],\n",
       "       [0.93, 0.07],\n",
       "       [0.86, 0.14],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.16, 0.84],\n",
       "       [0.64, 0.36],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.19, 0.81],\n",
       "       [0.93, 0.07],\n",
       "       [0.27, 0.73],\n",
       "       [0.28, 0.72],\n",
       "       [0.73, 0.27],\n",
       "       [0.52, 0.48],\n",
       "       [0.35, 0.65],\n",
       "       [0.03, 0.97],\n",
       "       [0.43, 0.57],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.11, 0.89],\n",
       "       [0.03, 0.97],\n",
       "       [0.15, 0.85],\n",
       "       [0.76, 0.24],\n",
       "       [0.18, 0.82],\n",
       "       [0.52, 0.48],\n",
       "       [0.28, 0.72],\n",
       "       [0.73, 0.27],\n",
       "       [0.66, 0.34],\n",
       "       [0.86, 0.14],\n",
       "       [0.68, 0.32],\n",
       "       [0.13, 0.87],\n",
       "       [0.11, 0.89],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.57, 0.43],\n",
       "       [0.57, 0.43],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.64, 0.36],\n",
       "       [0.69, 0.31],\n",
       "       [0.62, 0.38],\n",
       "       [0.28, 0.72],\n",
       "       [0.71, 0.29],\n",
       "       [0.37, 0.63],\n",
       "       [0.67, 0.33],\n",
       "       [0.65, 0.35],\n",
       "       [0.12, 0.88],\n",
       "       [0.72, 0.28],\n",
       "       [0.64, 0.36],\n",
       "       [0.11, 0.89],\n",
       "       [0.06, 0.94],\n",
       "       [0.02, 0.98],\n",
       "       [0.41, 0.59],\n",
       "       [0.06, 0.94],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.76, 0.24],\n",
       "       [0.43, 0.57],\n",
       "       [0.29, 0.71],\n",
       "       [0.19, 0.81],\n",
       "       [0.76, 0.24],\n",
       "       [0.61, 0.39],\n",
       "       [0.13, 0.87],\n",
       "       [0.42, 0.58]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probablity\n",
    "pred_prob_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applicability domain threshold\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc maximum predicted probability for each row (compound) and compare to the threshold\n",
    "da = np.amax(pred_prob_rf, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc coverage\n",
    "coverage = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "accuracy_da = accuracy_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "mcc_da = matthews_corrcoef(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "kappa_da = cohen_kappa_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "coverage_da = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy_DA = ', 0.8857142857142857)\n",
      "('MCC_DA = ', 0.7568742608653405)\n",
      "('Kappa_DA = ', 0.7554585152838428)\n",
      "('Coverage_DA = ', 0)\n"
     ]
    }
   ],
   "source": [
    "# print statistics (da)\n",
    "print(\"Accuracy_DA = \", accuracy_da)\n",
    "print(\"MCC_DA = \", mcc_da)\n",
    "print(\"Kappa_DA = \", kappa_da)\n",
    "print(\"Coverage_DA = \", coverage_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "#ROC curve\n",
    "\n",
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "# we pass y_test and y_pred_prob\n",
    "# we do not use y_pred_class, because it will give incorrect results without generating an error\n",
    "# roc_curve returns 3 objects fpr, tpr, thresholds\n",
    "# fpr: false positive rate\n",
    "# tpr: true positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the predicted probabilities for class 1\n",
    "y_pred_prob = rf.predict_proba(x_ts)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_ts, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEXCAYAAABcRGizAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XlYlFX/BvCbXQUFRRAUEVfEFZdcSQRMSR1x300zc01aSVFzSUtx6c3ILDPXSFNTSfOV3FDRLDVfwxpwAwUVEFRg2AZmzu8Pfw0RyzMgswj357q8LuaZM2e+zxmvuefZzmMihBAgIiIqg6mhCyAiIuPHsCAiIkkMCyIiksSwICIiSQwLIiKSxLAgIiJJ5oYugKgy+Pr64t69e0WWWVtbw8PDA/PmzUOHDh2KPHf69Gl88803uHbtGkxMTODu7o5XXnkF/v7+xfr+66+/8OWXX+LSpUvIyclBs2bNMGXKFMhkMp2uE5Ex4ZYFVRnvvPMOoqKiEBUVhbNnz2Lbtm2wsLDA66+/jqysLE27LVu2YO7cuejZsyf27t2LvXv3on///ggODsbq1auL9Hn69GmMGzcOzs7O2Lx5Mw4cOACZTIbg4GB88803+l5FIsMRRFWAj4+P2LlzZ7HlDx48EK1atRLHjx8XQggRExMjPDw8RGRkZLG2v/76q3B3dxfnz58XQgihUChEjx49RGhoaLG2X331lejQoYNIS0ur5DUhMk7csqAqzdLSEgBgZmYGANi7dy9at24Nb2/vYm27deuG3r17Y9euXQCAU6dOITMzE1OmTCnWdvz48diyZQvq1KlT4vveu3cPs2fPRufOndGrVy+sWLEC+fn5AAB3d3ecOnVK0/bXX3+Fu7u7ZuvH3d0dn376KXr16oUhQ4Zg/PjxWLlyZZH+P/roI0ydOhUAoFAo8MEHH6Bbt27o3r07AgMDkZycXJ5hIpLEsKAq6/Hjx1i0aBEcHBzQtWtXAMAff/yBjh07lvqa7t2748qVKwAAuVyOpk2bwsbGplg7GxsbdOnSBebmxQ/7KZVKTJ06FXl5eQgLC0NoaChOnjyJzz//XOvaDx06hO3btyMkJASDBw/G0aNHIf5/Zh61Wo2jR49qjpksXrwYcXFx2Lx5M3bu3AkTExNMmzYNBQUFWr8fkRQe4KYqY9WqVVi3bh2Ap1+oKpUKXbt2xdatWzVf+Onp6bC1tS21Dzs7Ozx+/BgAkJGRUWJQSDl//jzu3buHXbt2oV69egCAZcuWISEhQes+xowZg5YtWwIAnJyc8PHHH+PKlSvo3LkzLl26hPT0dLz00ktISEjATz/9hDNnzqBBgwYAgDVr1qB79+44e/YsfHx8yl0/UUkYFlRlzJgxA0OGDIFSqcR3332HY8eO4Y033tB86QKAra0tFApFqX1kZGSgbt26AIC6desiIyOj3HXcvHkTjRo10gQFALz44ovl6qNx48aav+vWrYvevXvjv//9Lzp37oyffvoJPj4+sLGxwcWLFwGg2FlcOTk5iIuLY1hQpeFuKKoy6tatiyZNmqBly5ZYsmQJunTpglmzZuHBgweaNp6envj9999L7ePSpUvw9PQEAHTo0AFxcXElhktmZiYmTZqE6OjoYs9ZWFiUq26VSlVsWY0aNYo8lslkiIiIQH5+Pn7++WfNLiiVSgULCwscOHAABw8e1PyLiIjA8OHDy1UHUVkYFlRlLVmyBGZmZli6dKlm2ZgxY3D9+nVEREQUa3/58mWcOXMG48aNAwB4eXmhXr162Lp1a7G2u3fvxpUrV9CoUaNiz7m5ueH+/ft48uSJZtnBgwcxcuRIAE/DJDMzU/OcNrun/Pz8kJmZiR07dqCgoAB9+vQBADRr1gz5+fnIyclBkyZN0KRJEzg4OGD16tWIj4+X7JdIWwwLqrLq1auHd999F5GRkTh+/DgAoHnz5ggODkZQUBA2btyIW7du4e7du/j2228xY8YMTJ48Gb169QLw9Nf90qVL8dVXX2HVqlWIjY3FrVu3sHHjRqxfvx5BQUFFdjX9zcvLC02aNMH8+fNx/fp1XLp0CaGhoZozsNq3b4+tW7fi1q1b+OWXX7BlyxbJdalZsyb8/Pzw+eefY8CAAZqzvJo1awZfX1+8//77uHTpEm7duoV58+bh6tWraNasWWUNJRGvs6CqobTrLNRqtRg7dqzw8fER2dnZmuXnzp0TU6dOFd26dROdO3cW48ePF0eOHCmx7wsXLoipU6eK7t27C09PTzFy5Ejx008/lVnPnTt3xLRp00SHDh1E7969xZo1a0R+fr4QQoi//vpLjBgxQrRt21YEBASIiIgI0apVK6FQKIQQQrRq1UqcPHmyWJ+RkZGiVatW4pdffimyPD09XcyfP19069ZNeHp6ismTJ4vY2NiyB4yonEyE4J3yiIiobNwNRUREknQeFkIIzJs3r9R5dCIjIyGTyTBgwAAEBgaWeVojEREZhk7D4tatW5g8eXKJZ54AwKNHjxAcHIzQ0FBERESgcePGWLt2rS5LIiKiCtBpWISFhWHUqFElTvsMAFFRUWjfvj3c3NwAAOPGjcOhQ4fAwyhERMZFp1dwL168GABw7ty5Ep9PSkqCk5OT5rGTkxMUCgWysrLKnGbh8uXLMDXl4Rbg6bQWHIunOBaFOBaFdDUWQghk5qmRml2AAnWld68T7g41NBedlpdBp/tQq9UwMTEptlzqgzU1NUWnTp10VdZzRS6Xw8PDw9BlGAWORSGORSFdjMW1e+lY8uOfuHznMTwb22GxrA2aO5R/HjF9MjUBEuNuVvj1Bg0LZ2dnXL16VfM4OTkZtra2qFWrlgGrIqKqKjdfhdikTFy7n45r99Jx70luufvIL1DjQlwa6tWyxOqRHTCyswtMTYv/6K1qDBoWXl5eCAkJQXx8PNzc3LB79274+fkZsiQiqiJylCrIkzJwPCYdW/+8iuh7GbiRnIkC9dNjorY1LeBmX6vEvRtSXuvdFHP9WsK2ZvnmAXue6T0soqOjsWjRIoSHh8Pe3h4rV65EYGAg8vPz4erqipCQEH2XRETPuay8AsgfZCD6Xjqu3cvAtXvpuPlQAdX/B0M9a0u0a2QL39YOaNfQFu0a2cKlbs0KBUV1pZewWLVqlebv9u3bIzw8XPPY29u7xLuWEVHVk1egwq+3H+FkTApOxqTg7qPsSn+P+jZWaN+oDga0bYC2jWxRM+chXuzSjsHwjHg/CyLSqZTMXETGPMSJmGScvZGKbKUKVuam8GpRH0M9G1bKl7iluSlaO9VGu0a2aFCn6PTucvljBkUlYFgQEYCnp4JeTUzHk2xlJfQF/JGYjpMxybiamA4AcLatgWGdGsHPwxE9m9VHTUuzZ34f0h+GBREBADaduY2V/42ptP5MTIBOje0QNMAdvq0d0dqpNn/hP8cYFkSEiD+TsOpoDAa2d8K0FyvnPhhN6tWCvY1VpfRFhsewIKrmrt1Lx1u7/4cOLnb4ZLQnalhw9xAVx/kAiKqx5IxcTNt+CXVrWeDrV7owKKhU3LIgqqaylQWYtv0SMnPzsW9WLzjWriH9Iqq2GBZEeiSEgPxBJk7GJCMy9iEeZT37mUclyVMqYfVTcpltFHkFeKjIw+ZXusLDuY5O6qCqg2FBpGO5+Sqcv5WKE/KnF6I9SH86H1EHF1u0bWSrk/fMSE9HHVvpvvu3aQA/jwY6qYGqFoYFkQ48SM95epWyPAXnbqUiN1+NWpZmeLFlfbzdrxX6tnbQ6W4fzjpLlY1hQVQJVGqBq4lPcFKeghMxKZA/yAAANK5XE2NfcIVva0d0b1YPVuY8gEzPJ4YFUQVl5ubj7I2nu5ciY1OQlqWEmakJujSpi+CXW8PPwxHNHWx4IRpVCQwLonLIVhbg+4sJOC5Pxq+3H6FALWBb0wI+7g7w9WgA75YOsK1VfaatpuqDYUGkBSEEDv/xAB8fkeNBei5aNbDBtBebwc/DEZ0a28HcjJcsUdXGsCCSEJuUiSU/XsOF24/QtmEdfD6+E7o0qWfosoj0imFB9P/iUrOwJiIGygKhWZavUiPqZipq1zDHR8PaYewLrjCrBrfQJPo3hgXR/zt3MxVHopPQqoENzE0LdytN6O6Kt/u1Ql1rSwNWR2RYDAuif/l2WndOfUH0LzwqR0REkhgWREQkiWFBRESSGBZEAE7FpODrs7dhaW6KmrynA1ExPMBN1dqdtCwsP/wXjstT0MzBGlunvIDaNXgFNtG/SYbFyZMncezYMcTFxcHU1BTNmjWDv78/vLy89FEfkU7kKFXYGHkTX565DQtTEywY2BpTejWFpTk3tolKUmpY3L59G8HBwahTpw569+4NPz8/mJubIzExETt37sTnn3+OFStWoEWLFvqsl+iZCCFw9FoSVvwkx70nORjq2RDBAz3QoA5PlSUqS6lhsXHjRqxduxaNGzcu9tzEiRNx9+5drF+/HuvWrdNpgUSV5WZKJpb++BeibqaitVNt7JnRE92actoOIm2UGhZr1qwBABQUFMDcvHgzV1dXBgUZvcdZSkReT8EJeQqOXktCLUszfBjQFuO7uXLyP6JykDxm4ePjg+HDh2P06NFo1KiRPmoiqjAhBK4nK3AiJhkn5Sn4/e5jqAVQ38YKE7q7ItCvJextrAxdJtFzRzIs9uzZg71792LixIlo1aoVxo0bB29vb97QhQwmTZGHAnXhZH9CAPKkDPxwIRVXwk/h3pMcAED7RraY69sSvq0d0b6RLUw5ASBRhUmGhbOzMwIDA/HGG2/g5MmTWL58OT788EOMHz8er7zyCiwtObka6UfCo2x8ePgvHPsrucTnrcxN0KeVI+b6toBPa0cetCaqRFpdZ3Hr1i3s3bsXhw8fhqenJ4YPH46zZ8/izTffxMaNG3VdI1VzOUoVNp6+hS9P34K5qQnm+raAs23NIm0a2tVA3fyH6NiurYGqJKraJMNi3LhxSEhIwMiRI7Fv3z44OTkBAPr27YsePXrovECqnjJz8xGfmo0/76cj9ORN3HuSA1nHhlgwsHWxoPibXJ6m5yqJqg/JsBg/fjz8/f1hYVF4VWt6ejpsbW1x6tQpnRZHVVtegQp307JxOzULcalZiE/N0vz9MDNP0869QW3ser0Heja3N2C1RNWbZFhs2bIFMpmsyLIJEybg8OHDsLa21llhVDWo1AL3n+Qg7v9DIE4TCArce5yDfxynRn0bSzStbw0fdwc0rW+DpvWt0bS+NVo42vDudEQGVmpYTJ48GdHR0cjNzUXnzp01y9VqNdq3b6+X4uj59CRbiQ/C/0RsUgbi07KhLFBrnrO2NENTB2t4Nq6LYZ1c0Oz/A8GtvjVsa3JOJiJjVWpYbNiwAU+ePMGCBQuwcuXKwheYm8PBwUGrziMjI7Fu3ToolUq4u7vj448/ho2NTZE2x44dw2effQZTU1PY2tpixYoVcHV1reDqkDGIvpeOQ1fvo3vTevBxd9RsITR1sIaDjRVPuyZ6DpV5CauLiws+++wzWFtba/5ZWVkhIyNDsuNHjx4hODgYoaGhiIiIQOPGjbF27doibXJzcxEUFITPP/8c4eHh8PX1xYoVK55tjchoBA1wR/BAD4zt5oruzezhWLsGg4LoOVXqlsWkSZNw4MAB9OjRAyYmJhCicOeyiYkJ5HJ5mR1HRUWhffv2cHNzA/D0rKqAgAAsWbJE84WhUqkghEBmZiYAICsrC1ZWvLr2eZeVpwIAMBeIqo5Sw+LAgQMAgL/++gumpuWfQycpKUlzmi0AODk5QaFQICsrS7MrytraGsuWLcPYsWNhZ2cHtVqNXbt2SfatVqslw6q6yM3NNaqxEEJgfcR91K1pBtP0B5DLS76ATheMbSwMiWNRiGNROSTPhurbty9GjhyJkSNHomHDhlp3rFarS9zl8M/giY2NxYYNG3DkyBG4urpix44dmDt3LsLDw8vcXWFqagoPDw+ta6nK5HK5UY3F4T/uQ/4wDiEj2qNTB/0eezK2sTAkjkUhjkWhZwlNyU2GrVu3QqlUYty4cXjttddw9OhRFBQUSHbs7OyMlJQUzePk5GTY2tqiVq1ammVRUVHo3Lmz5oD2hAkTcOPGDTx+/Lgi60IGlpuvwqr/xqC1U22M7FJ8ansien5JhkXz5s3x3nvv4dSpU3jllVewZcsW9OnTR7JjLy8vXL16FfHx8QCA3bt3w8/Pr0ibNm3a4OLFi0hNTQUAHD9+HC4uLqhXj/cYeB5tOx+PxMc5WDSoDa+LIKpitJobKi0tDT/++CMOHDgAIQRmzZol+Rp7e3usXLkSgYGByM/Ph6urK0JCQhAdHY1FixYhPDwcPXv2xGuvvYZJkybBwsICtra2+OKLL555pUj/UhV52HDyJvxaO8KrZX1Dl0NElUwyLGbOnIkrV67gpZdewvLly9GxY0etO/f29oa3t3eRZXZ2dggPD9c8njBhAiZMmFCOkskYfXr8OrLzVQgeyH3DRFWRZFj4+vpi3bp1nNqDSnU9ORPf/XoXk3o0QQtHG+kXENFzp9SwCA8PR0BAABQKBfbs2VPs+VdffVWnhdHzY01ELGyszPFWv1aGLoWIdKTUsLhz5w4A4MaNG3orhp5PN5Iz4e3uiLrWvBEWUVVValgEBgYCAPz8/NCvX78izx08eFC3VZHRyM1XIVupKrONSgjw5Ceiqq3UsDh58iQKCgqwevVqCCE0030UFBQgNDQUQ4cO1VuRZBgqtYBXyCmkKvIk23Zz470miKqyUsNCLpfjwoULSEtLw44dOwpfYG6OKVOm6KM2MrACtRqpijz083DEiy3LnmnYx91RT1URkSGUGhZz5szBnDlzEBYWxlNbq7lOrnUxuZebocsgIgOSPBsqLy8PW7duLfY8z4YiIqo+eDYUERFJkjwb6p93yVMqlUhNTS3X7LP0/EpTKA1dAhEZCcmJBI8dO4bly5dDoVDA398fAQEB2L59uz5qIwPJV6mx+ext9P/PGViamaJrk7qGLomIDEwyLL766iuMHj0aP//8Mzw9PXHq1KkicztR1RJ1IxUvrz+LFT/J0a1pPfz8dh90b8bTYomqO8mwEELA3d0d58+fR58+fWBjY1PkFqtUdYT9egcTv/kV+So1vpncFVumvAC3+pwTjIi0CAtTU1McOXIEUVFR6N27N06fPl3mXezo+XU14QnsrS0R8VYf+Hk0MHQ5RGREJGednTdvHj7//HO8/fbbcHBwwMaNG7Fw4UJ91EY6FpeahczcfM3jR1lKWJqbooaFmQGrIiJjJBkWXbt2xbZt2zSPd+/erct6SE/iU7Pgszay2PJmDtztRETFSYbFlStX8MknnyA9Pb3IsYpDhw7ptDDSrczcp/dRn+vbAp6N7TTLmzvwfhREVJxkWCxevBjDhw9HmzZteKyiCuroYsfjE0QkSTIszM3NObUHEVE1J3k2VMuWLREbG6uPWoiIyEhJblkkJCRgxIgRaNiwIaysrDTLecyCiKj6kAyLt99+Wx91EBGREZPcDdWtWzfUqFEDt2/fhqenJywsLNCtWzd91EZEREZCMiz279+P4OBgbN68GZmZmZg9ezb27Nmjj9qIiMhISIbFzp078f3338PGxgb29vbYv38/Z50lIqpmtJobysam8EItZ2dnmJlxOojnXU6+ytAlENFzRPIAt52dHeRyueaCvB9//BG2trY6L4wqlxACN1IUOCFPwcmYZFy+8xgAUKemhYErI6LngWRYLFiwAG+++Sbu3r0LLy8vWFlZ4YsvvtBHbfSMcvNV+DXuEU7Kk3EiJgWJj3MAAG0b1sEbPi3Qr00DdHCxk+iFiEiLsGjevDnCw8MRHx8PlUqFpk2bwsKCv0aNWVJ6Lpb8eA1nb6QiW6lCDQtTeLWoj9l9W8CntQOcbWsaukQies6UGRa3b9+Gra0t7O3tkZOTg4MHD6Jt27YYNmyYvuqjCoi6mYqIP5MxsosLBnVwRs9m9px2nIieSakHuE+cOIFx48YhPj4eycnJmDx5MnJzc3HgwIEiU5aT8XrTryV83B0ZFET0zErdsti0aRO+++47NG/eHN988w08PDywYsUK5OTkYMyYMZgyZYoey6SyTNt+EX8kpmse80wnIqpspYZFTk4OmjdvDgC4fPky+vTpAwCoWbMm78FtZM7dTEMT+1ro5Fp4sNre2gqN7HhsgogqR6lh8XcgCCFw5coVTJs2TfNcdna27iujcunTygELBnoYugwiqqJKDYsWLVpg+/btyMvLg7m5OTw9PSGEwPbt29GuXTutOo+MjMS6deugVCrh7u6Ojz/+uMgFfgAQGxuLFStWIDMzE6ampvjwww+17p+IiPSj1APcCxYswPnz53H06FGsXbtW80W+a9cuvP/++5IdP3r0CMHBwQgNDUVERAQaN26MtWvXFmmTk5OD1157DdOmTcPBgwcxe/ZsvPfee8++VkREVKlK3bJwcHDAV199VWTZ3LlzsWjRIq2m+4iKikL79u3h5uYGABg3bhwCAgKwZMkSzdXg586dQ+PGjeHt7Q0A8PPzg4uLS0XXpVqIScrA6diH+PuoUUrKE+Sr1AatiYiqvlLD4tNPP8Xs2bNhaWmpWVavXj3N33l5efjiiy9Kvd9FUlISnJycNI+dnJygUCiQlZWl2RUVFxcHBwcHLFiwADExMahTpw6CgoIki1ar1ZDL5dJrV4Vk5qmw83+P8VNsBtQlnF9gkZdR7cbk33Jzc6v9GPyNY1GIY1E5Sg2Lzp07Y8SIEXjxxRfh4+MDV1dXCCFw9+5dnDlzBpGRkXjnnXdK7VitVmu2IP7J1LRwz1dBQQFOnz6NHTt2oGPHjjh+/DimT5+OU6dOFQmpkvrw8KgeB3PVaoE9lxKwOiIWT7KVmNijCeb6toSN1dOPLiY2Bh6tW/NaCgByubza/L+QwrEoxLEo9CyhWWpY9OnTB126dEFYWBhWrVqF27dvw8zMDG5ubhgwYAB2795d7GD1Pzk7O+Pq1auax8nJybC1tUWtWrU0yxwdHdG8eXN07NgRANCvXz8sWrQICQkJmtN2q7P/JTzBkvBruJqYjhfc6mLZkO5o07BOkTY1zE0ZFESkc2VO92FtbY3p06dj+vTp5e7Yy8sLISEhiI+Ph5ubG3bv3g0/P78ibfr06YOQkBBcu3YN7dq1w8WLF2FiYlLtj1ukKvKw+mgM9lxKhGNtK6wf64khHRuWuKVGRKQPkhMJVpS9vT1WrlyJwMBA5Ofnw9XVFSEhIYiOjsaiRYsQHh4OBwcHbNiwAcuWLUNOTg4sLS0RGhoKKysrXZVl1ApUauy8cAefHLuOHKUKM/o0w1y/wl1ORESGotNvIW9vb82ZTn+zs7NDeHi45vELL7yAvXv36rKM58aKn+TYdj4eL7asjyWytmjhWPpuPiIifeJPViNyOzUL7RrVwY6p3bjLiYiMiuRtVYGnp8GePn0aKpUK9+/f13VN1Zq5qSmDgoiMjmRYREZGYuzYsVi2bBnS0tIwaNAgHD9+XB+1ERGRkZAMiw0bNmDPnj2oU6cOHB0d8d133+Gzzz7TR21ERGQkJMNCpVLB0dFR89jDw4O7SYiIqhnJsKhZsybu37+vCYhLly5V21NbiYiqK8mzod59911MnToVDx8+xJgxYxAfH4/Q0FB91EZEREZCMiw6d+6MPXv24MqVK1Cr1ejYsWORCQWru5Mxyfj0+A08ylI+c18PM/Pg4VxHuiERkZ5JhsW0adOwefPmIhfXjR49Gnv27NFpYcbuTloWPjz0F07EpKBZfWt0a1o5AerXukGl9ENEVJlKDYvAwEDExcUhISEBMplMs7ygoKDMGWGruhylCl9E3sRXp2/DwswECwa2xpReTWFprtUlK0REz6VSw+L999/HvXv38MEHH+CDDz7QLDczM0OLFi30UpwxWvdzLDZHxWFYp0aY/3JrNKhTw9AlERHpXKlh4eLiAhcXFxw9erTIPSgAIDs7W+eFGauUzDy42dfCf8Z4GroUIiK9kTxmcfLkSXz22WfIzs6GEAJqtRpPnjzBlStX9FGfXl25+xhX7j4ps82thwpeZ0JE1Y5kWKxevRpvvfUWdu3ahddffx3Hjx+HtbW1PmrTuw/Cr+HavQzJdl4t6uuhGiIi4yEZFjVr1sTAgQMhl8thZWWFpUuXYtCgQZg3b54+6tOrApWAb2tH/Gd02buYrK14Zzoiql4kw8LKygpKpRKurq6Qy+Xo3r17ld4NY2FmAttaFoYug4jIqEiGha+vL6ZPn46QkBCMGTMGly9fRt26dfVRGxERGQnJsJg5cyaGDBmCBg0aYMOGDbh06VKR6y6IiKjqK/NKsri4OKSkpKBhw4YAgLZt28Lf3x8fffSRXoojIiLjUGpYbN68GcOHD8eAAQNw8eJFAMC2bdswcOBAPHz4UG8FEhGR4ZW6G+r777/HkSNH8ODBA2zZsgW7du3Cb7/9hqVLl3I3FBFRNVPqlkXNmjXh7OyMzp0749KlS8jOzsaRI0cYFERE1VCpWxZmZoXXEtjY2ODTTz9FjRqcB4mIqDrSaqrU2rVrMyiIiKqxUrcs0tLSsHXr1mJ//+3VV1/VbWVERGQ0Sg2L3r174/r168X+JiKi6qfUsFi5cqU+69C5mTsv43pKZpltEh/loIl9LT1VRET0/JC8gruqOPpnElo62sDdqXapbdo418HILi56rIqI6PlQbcICAF5u74x3Xmpl6DKIiJ47vHE0ERFJ0ios/vjjD+zevRtKpbJK3iGPiIjKJhkW+/fvR3BwMDZv3ozMzEzMnj0be/bs0UdtRERkJCTDYufOnfj+++9hY2MDe3t77N+/H9u3b9dHbUREZCQkw8LU1BQ2Njaax87OzkWmAiEioqpPMizs7Owgl8s1t1L98ccfYWtrq/PCiIjIeEiGxYIFCxAUFIRbt27By8sL69evx6JFi7TqPDIyEjKZDAMGDEBgYCAUCkWpbY8fP45OnTppXzkREemN5HUWzZo1Q3h4OOLj46FSqdC0aVNYWFhIdvzo0SMEBwdj165dcHNzw5o1a7B27VosXbq0WNv4+HiEhIRUaAWIiEj3JLcsvL29sWHDBtSoUQOtWrXSKigAICoqCu3bt4ebmxsAYNy+A7vaAAAaHUlEQVS4cTh06BCEEEXa5eTkICgoCPPnzy9/9UREpBeSWxbbtm3D/v37MX78eLRo0QKjRo1Cv379YG5e9kuTkpLg5OSkeezk5ASFQoGsrKwiB8wXL16MMWPGwN3dXeui1Wo15HK51u3/lpr6EHK5qtyvM2a5ubkVGouqiGNRiGNRiGNRObTaDfXee+/hnXfewdmzZ7FhwwZ8+OGHOH/+fJmvU6vVmoPi/2RqWrgxExYWBnNzc4wcORKJiYlaF21qagoPDw+t2z91G/XrO8DDo2pN9yGXyyswFlUTx6IQx6IQx6LQs4SmVnNDpaWl4ccff8SBAwcghMCsWbMkX+Ps7IyrV69qHicnJ8PW1ha1ahXO6nrgwAHk5uYiICAA+fn5mr83bdqEBg0aVGB1ikvJyMXK/8YAAOxqarcLjYiIipIMi5kzZ+LKlSt46aWXsHz5cnTs2FGrjr28vBASEoL4+Hi4ublh9+7d8PPzK9Jm3759mr8TExMhk8kQHh5ezlUombJAjW3n47D++A3kqwTe8GmB8d1dK6VvIqLqRjIsfH19sW7dOlhbW5erY3t7e6xcuRKBgYHIz8+Hq6srQkJCEB0djUWLFlVaKJTkRnImZn57GbceZsGvtSM+GNwGbvXLVz8RERUqNSzCw8MREBAAhUJR4lxQ2txW1dvbG97e3kWW2dnZlRgULi4ulTZJYdivd5HwOAffTO4KP4/K2Z1FRFSdlRoWd+7cAQDcuHFDb8VUFpVawMbKnEFBRFRJSg2LwMBAAICfnx/69etX5LmDBw/qtioiIjIqpYbFyZMnUVBQgNWrV0MIobmYrqCgAKGhoRg6dKjeiiQiIsMqNSzkcjkuXLiAtLQ07Nixo/AF5uaYMmWKPmojIiIjUWpYzJkzB3PmzEFYWBgmTJigz5qIiMjISJ4NlZeXh61btxZ7XpuzoYiIqGqokmdDERFR5ZI8G2rlypWaZUqlEqmpqWjYsKHuKyMiIqMhOUX5sWPHsHz5cigUCvj7+yMgIID34CYiqmYkw+Krr77C6NGj8fPPP8PT0xOnTp3S6VQdRERkfCTDQggBd3d3nD9/Hn369IGNjU2xGxgREVHVJhkWpqamOHLkCM6ePYvevXvj9OnTJd6ngoiIqi7JsJg3bx727NmDd999Fw4ODti4cSMWLVqkj9qIiMhISE5R3rVrV2zbtg337t3DnTt3sHv3bn3URURERkQyLOLj4zFnzhykpKRArVajbt26+Oqrr9C8eXN91EdEREZAcjfU8uXLMW3aNFy8eBGXL1/GrFmzsGzZMn3URkRERkIyLNLS0jBs2DDN4xEjRuDx48c6LYqIiIyLZFioVCo8efJE8/jRo0c6LYiIiIyP5DGLiRMnYsyYMXj55ZdhYmKCI0eOYPLkyfqojYiIjIRkWIwZMwZNmjTB2bNnoVarsWTJEvTq1UsftRERkZEoMyxOnz6N27dv44UXXkBQUJC+aiIiIiNT6jGLTZs2Yfny5bh69SpmzpyJQ4cO6bMuIiIyIqVuWRw6dAgHDx6EjY0Nbt++jQULFkAmk+mzNiIiMhKlblmYm5vDxsYGANCsWTNkZWXprSgiIjIukqfO/s3cXPJYOBERVVGlJoBKpUJ6erpmOvJ/P7azs9NPhUREZHClhsX169fRo0ePIveu6N69OwDAxMQEcrlc99UREZFRKDUsYmJi9FkHEREZMa2PWRARUfXFsCAiIkkMCyIikqRVWOTm5iI2NhZCCOTk5Oi6JiIiMjKSYfG///0P/fr1w4wZM5CcnIy+ffvi999/10dtRERkJCTDYvXq1di2bRvs7Ozg5OSE1atX46OPPtJHbUREZCQkwyI3NxctWrTQPPb29oZKpdKq88jISMhkMgwYMACBgYFQKBTF2oSHh2PIkCEICAjA2LFjER0dXY7yiYhIHyTDwtzcHOnp6TAxMQEA3L59W6uOHz16hODgYISGhiIiIgKNGzfG2rVri7S5ffs21qxZg82bNyM8PByzZs3C3LlzK7AaRESkS5JhMWvWLEycOBFJSUl45513MG7cOMyaNUuy46ioKLRv3x5ubm4AgHHjxuHQoUNFrgi3tLTEihUr4OjoCABo164dUlNToVQqK7g6TwkI6UZERKQ1ydkBfXx80KxZM5w7dw5qtRpz5sxB8+bNJTtOSkqCk5OT5rGTkxMUCgWysrI0s9m6uLjAxcUFACCEwMqVK+Hr6wtLS8sy+1ar1aVON/IwqwA/Xb2HujXNqsWUJLm5udViPbXBsSjEsSjEsagckmHx5MkT2NraYuDAgUWWSU0kqFarNbuu/snUtPjGTHZ2NubPn4+kpCRs3rxZsmhTU1N4eHgUW56VV4B3vvwF+WoTfDm5B1o1qC3Z1/NOLpeXOBbVEceiEMeiEMei0LOEpmRY9OjRo9iXvoODA86cOVPm65ydnXH16lXN4+TkZNja2qJWrVpF2t2/fx8zZ85E8+bNsWPHDtSoUaM89Wuo1AJv7v4fYpMysGXKC9UiKIiI9EUyLP45oaBSqcThw4cRFxcn2bGXlxdCQkIQHx8PNzc37N69G35+fkXaKBQKTJo0CcOGDcMbb7xRgfILhRyNwXF5MpYNaYu+7o7P1BcRERVVruk+LC0tMXz4cJw7d06yrb29PVauXInAwEC8/PLLuH79OubNm4fo6GgEBAQAAMLCwnD//n0cO3YMAQEBmn+PHz8u10p8f/EuNp25jVd6NsHkXm7lei0REUnT6pjF34QQuHbtGjIyMrTq3NvbG97e3kWW2dnZITw8HAAwY8YMzJgxozz1FnP7oQILD1zDiy3rY/HgNs/UFxERlUzrYxZ/n/Jqb2+PhQsX6rwwbe345Q5MTUzwyWhPmJtxXkQiIl2QDIt9+/ahXbt2+qil3BR5Bdh3ORGDOjjDobaVocshIqqyJH+KBwUF6aOOCjnweyIUeQV4pWcTQ5dCRFSlSYaFu7s7Dh06hPv37+PJkyeaf4YmhMD2X+6gg4stPBuXfc0HERE9G8ndUCdOnMDRo0eLLDMxMTH4FZG/3ErDzRQF1o7qWOLFf0REVHlKDQulUglLS0ujnQV2+y/xqFvLAoM7OBu6FCKiKq/U3VBjxozRZx3lkq8SOPZXMsZ2c0UNCzNDl0NEVOWVGhb/nB3W2KTnPr2fxoTurgauhIioeih1N1ReXh7++uuvUkOjbdu2OitKSnqeCv08GsClbi3pxkRE9MxKDYuEhATMnTu3xLAwMTHBiRMndFpYWVRqcFoPIiI9KjUsWrRogYMHD+qzFq1ZmgG9mtsbugwiomrjuZwfw9zUhKfLEhHpUalh0bVrV33WQURERqzUsFi0aJE+6yAiIiP2XO6GIiIi/WJYEBGRJIYFERFJYlgQEZEkhgUREUliWBARkSSGBRERSWJYEBGRJIYFERFJYlgQEZEkhgUREUliWBARkSSGBRERSWJYEBGRJIYFERFJYlgQEZEkhgUREUliWBARkSSGBRERSWJYEBGRJIYFERFJ0mlYREZGQiaTYcCAAQgMDIRCoahQGyIiMiydhcWjR48QHByM0NBQREREoHHjxli7dm252xARkeHpLCyioqLQvn17uLm5AQDGjRuHQ4cOQQhRrjZERGR45rrqOCkpCU5OTprHTk5OUCgUyMrKgo2NjdZtStLYzgpyuVxXpT93OBaFOBaFOBaFOBZP5eXlVfi1OgsLtVoNExOTYstNTU3L1aYknp6ez14gERFpTWe7oZydnZGSkqJ5nJycDFtbW9SqVatcbYiIyPB0FhZeXl64evUq4uPjAQC7d++Gn59fudsQEZHhmQgdHk0+ffo01q1bh/z8fLi6uiIkJAQJCQlYtGgRwsPDS21jZ2enq5KIiKgCdBoWRERUNfAKbiIiksSwICIiSUYbFpwqpJA26xkeHo4hQ4YgICAAY8eORXR0tAEq1b3yfObHjx9Hp06d9FidfmkzFrGxsZg0aRKGDh2K4cOH49q1awaoVPe0GYtjx45BJpMhICAAr7zyCu7evWuASvVDCIF58+bhm2++KfH5Cn13CiOUlpYmevToIeLi4oQQQqxevVosWbKk3G2qAm3W89atW6J3794iOTlZCCFEZGSk8Pb21m+helCezzwuLk7069dPeHp66q9APdJmLLKzs0Xv3r1FZGSkEEKIY8eOiQEDBui5Ut3TZixycnJEx44dRXx8vBBCiK1bt4rXX39dz5Xqx82bN8WkSZNEx44dxebNm4s9X9HvTqPcsuBUIYW0WU9LS0usWLECjo6OAIB27dohNTUVSqXSECXrjLafeU5ODoKCgjB//nwDVKkf2ozFuXPn0LhxY3h7ewMA/Pz88OmnnxqiXJ3SZixUKhWEEMjMzAQAZGVlwcrKyhDl6lxYWBhGjRoFf3//Ep+v6Henzq7gfha6nCrkeaPNerq4uMDFxQXA083PlStXwtfXF5aWlgapWVe0/cwXL16MMWPGwN3d3RBl6oU2YxEXFwcHBwcsWLAAMTExqFOnDoKCggxVss5oMxbW1tZYtmwZxo4dCzs7O6jVauzatctQJevU4sWLATz9sVCSin53GuWWhS6nCnnelGc9s7Oz8eabb+Lu3btYsWKFPsrTK23GIiwsDObm5hg5cqQ+S9M7bcaioKAAp0+fxpgxY7B//35MnDgR06dPr3JbnNqMRWxsLDZs2IAjR44gKioKM2fOxNy5c6vcnghtVPS70yi/WTlVSCFt1/P+/fsYO3YszMzMsGPHDtSpU0ffpeqcNmNx4MABREdHIyAgANOnT0dubi4CAgKQnJxsiJJ1RpuxcHR0RPPmzdGxY0cAQL9+/aBSqZCQkKD3enVJm7GIiopC586d4erqCgCYMGECbty4gcePH+u9XkOr6HenUYYFpwoppM16KhQKTJo0Cf3798d//vMf1KhRwwCV6p42Y7Fv3z4cPnwY4eHh2LRpE2rUqIHw8HA0aNDAABXrjjZj0adPHyQmJmrOgLp48SJMTEw0uyyrCm3Gok2bNrh48SJSU1MBPD1TzsXFBfXq1dN3uQZX4e/OSjn8rgORkZFCJpMJf39/MX36dPH48WPxxx9/iCFDhpTZpiqSGosvv/xStG7dWgwZMqTIv0ePHhm48sqnzf+LvyUkJFTZs6GE0G4sfvvtNzFy5EgxaNAgMWzYMHHx4kUDVqw72ozFt99+K/z9/YVMJhMTJ04U169fN2DFujdv3jzN2VCV8d3J6T6IiEiSUe6GIiIi48KwICIiSQwLIiKSxLAgIiJJDAsiIpLEsKji3N3dNTNt/v1v4cKFZb5m//79mDFjRqW8f2hoKHr06IGAgAAMHToUMpkMU6ZMQVxcXIX6S05OxtixYwEACQkJmDt3brHlzyoxMREeHh5Fxuyll17CpEmTtLqg7fPPP8fx48fL/b4qlQozZszQXAsAABkZGZDJZBWeRfjWrVuYPn06ZDIZZDIZJk6ciEuXLlWoLykLFy7E+fPnAQAbN25E3759ERwcXGR5SUr7TEvz9zilpaVVXvEkTUen+JKRaNWqlUhLSyvXa3744Qcxffr0Snn/zz77TCxbtqzIsh07dohhw4Y9c98XLlwQgwYNeuZ+/q2k6zPUarX48MMPxdtvvy35+okTJ4r//ve/5X7fTZs2FZklNDIyUvTv31+0bdtW/PHHH+XuTwghBg4cKH7++WfN499++0107txZ59ck+fr6VuiaDm0/099++03MnTu3IqVRBXHLohrbt28fRo0ahaFDh8LHxwffffddsTY///wzhg0bhuHDh2PUqFG4ePEiACAzMxPz58/H8OHDIZPJ8PHHH6OgoECr9+3Zs6dmyyIpKQkzZ86ETCbD4MGDsXnzZgBP5zVasmQJZDIZhg8fjsDAQGRlZSExMRGdOnWCSqXCokWLcPfuXbz22mtFlnt7exe5b8Nbb72lWbeNGzdi2LBhCAgIwOzZs7WeBiQvLw8pKSmwtbUF8HSSvldffRWjR4+Gj48PZs2ahby8PISFheHatWtYvXo1jh07BqVSiY8//hjDhg3DkCFDMH/+/BLvHZCTk4Pt27dj+PDhmmU7duzAmjVrNLMJV8TDhw+RnZ2tefzCCy/g008/hZmZGRITE+Hj44PFixcjICAAQ4YMKbLVUdpYPXz4ELNnz4a/vz8GDhyIHTt2AAAmTZqEo0eP4q233kJycjIWLlyII0eOaJYDwKlTpxAQEACZTIYxY8YgJiam1M9048aNePfddzX1XLp0CUOHDtWsx82bNyGXyys8NlROhk4r0q1WrVqJwYMHF7myOzU1VSgUCjF69GjNVd5XrlzR/Jr+55aFn5+fuHLlihBCiLNnz4rQ0FAhhBDz588XO3bsEEIIUVBQIN577z2xadOmYu//7y2L/Px8sXLlSjFjxgwhhBATJkwQW7ZsEUIIkZGRIWQymTh8+LC4ePGi8Pf3F2q1WgjxdM79y5cvF/nV/89fof9cvn79es17PnnyRHTr1k1kZGSIAwcOiLfeekvk5+cLIYTYvXu3mDZtWrGaExISNFfEDx48WPTs2VP4+/uLTz75RCgUCiGEEKtWrRIHDx4UQgihVCrF4MGDxdGjR4UQRbcsQkNDxapVqzTrsW7duhLvHXDy5EkxceLEkj5C4ePjU+Eti0OHDomuXbuK3r17i8DAQLFz507NVkVCQoJo1aqV+PHHH4UQT7dkevfuLZRKZZljNWfOHBESEiKEePqZDRo0SMTHxxdZ73/W/Pfyhw8fii5duog///xTCCFERESEeO2110r9TFNTU4tsBQUFBYldu3Zp1m358uVi/fr1FRoXKj+jnKKcKtf27dtLnAPnyy+/xOnTpxEfH4+YmJgiv0D/NmjQILzxxhvw9vZG79698frrrwN4eqet6Oho7Nu3DwCQm5tb6vsfOXIEly9fBgDk5+ejbdu2WL58ObKzs/H7779jy5YtAIDatWtj+PDhOHPmDBYuXAgzMzOMGjUKXl5eGDBgADp06IDExETJ9R0xYgRGjhyJ+fPn4/Dhw/D19UXt2rVx6tQpREdHY8SIEQCezr6Zk5NTYh9/zykFAGfPnkVQUBB8fHxgbW0NAAgKCsK5c+fw9ddfIz4+HikpKSWOX2RkJDIzMzX77PPz82Fvb1+s3e3btzWT3FWmwYMH46WXXsLly5dx8eJF/PDDD9i4cSO+//57AICtrS1kMhkAwNvbG2ZmZoiNjS1zrM6fP6+Z6rx27do4fPiwVrX8/vvvaNmyJdq0aQMA6N+/P/r371/qZ2pvb4++ffsiPDwcQ4cORVRUFJYsWaJ53sXFBVevXq3AqFBFMCyqqaSkJIwZMwajR49Gly5d4O/vj1OnThVr9/bbb2PEiBE4d+4c9u/fjy1btmDfvn1Qq9VYv349mjdvDuDpgdiSpj0GgIEDB2rm2P8nhUJRbIpotVqNgoIC1KlTB+Hh4fj9999x4cIFvPXWW3jttdc0N/IpS6NGjdCmTRtERkZi//79WLBggabvadOmYfz48QAApVKJ9PR0yf5efPFFvPrqq3jzzTfx008/wcbGBu+88w5UKhVefvll9O3bFw8ePChxumu1Wo0FCxZo6s7KykJeXl6xdiYmJlCr1ZK1/Nvrr7+umUE0MDCwyIRwt27dwoEDB/Dee++hV69e6NWrF958801MmTIFERERGDBgAMzMzIrVa2ZmVuZYmZubF/msExISULduXclazczMirxOCIHY2Ngy76EwYcIELF26FObm5ujfv78mrP+uo6rdksCYcaSrqWvXrqFevXqYPXs2vLy8NEGhUqk0bQoKCuDr64ucnByMGzcOS5YsQWxsLJRKJby8vLBt2zYIIaBUKjFr1ix8++235arBxsYGHTt2RFhYGICnx0EOHjyIXr164dSpU5gyZQo6deqEuXPnYujQocXuH21mZob8/PwS+x49ejS+/vpr5OTkoEuXLgCezra5b98+zTGD9evX4/3339eq1qlTp8La2hqfffYZgKdTXs+ZMwcDBw4EAFy9elUzdmZmZprjN15eXggLC4NSqYRarcYHH3yATz75pFj/TZs2rdDU4V9//TXCw8MRHh5ebObQ+vXrY8+ePZrjBQDw5MkTJCcna37dP3r0CGfOnAEAnDx5EhYWFmjVqlWZY9WzZ0/88MMPAJ5+ZpMnT9bMYFqWjh074tatW7hx4wYA4MSJE8VuxvTvz7Rz584wNTXFN998U+xst8TERDRr1kzyfalycMuimurduzf27dsHf39/mJiYoFu3bqhXrx7u3LmjaWNubo4FCxbgvffe0/ya/Pjjj2FpaYmFCxfio48+gkwmQ35+Pnr16oVp06aVu461a9fiww8/xP79+6FUKjUHtNVqNc6cOYPBgwejVq1asLW1xfLly4u8tkWLFrCyssLIkSPxn//8p8hzvr6+WLZsmWa3GQCMGjUKycnJGD16NExMTODs7IxVq1ZpVaeFhQU++OADTJs2DSNHjsTbb7+NOXPmoFatWrCxscELL7yAu3fvat77k08+QX5+PmbPno2QkBAMGzYMKpUKHh4eJd7utVevXli4cCEyMjIq7V4ktra22L59O9atW4fVq1ejZs2asLS0xIwZM9CzZ08kJibCysoK4eHhWLt2LWrUqIENGzZodv+VNlaLFy/G0qVLIZPJIITAjBkz0K5dO8l66tevj7Vr12LevHlQqVSwsbEp9rn98zPdu3cvTExMMHz4cBw5cgStW7cu0vbcuXNV8jaxxoqzzhIZiS+//BJmZmZFAk6XEhMTIZPJcOXKFb28X0UUFBTgjTfewJAhQzRbcQDw66+/IiwsTLOlR7rH3VBERmLq1Km4cOECHj58aOhSjMLNmzfRs2dP1K1bF/7+/prlKpUKmzdvxqJFiwxYXfXDLQsiIpLELQsiIpLEsCAiIkkMCyIiksSwICIiSQwLIiKS9H+AryOcjmnpfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#Model evaluation - confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_ts, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53 20]\n",
      " [20 60]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification error or misclassification rate\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26143790849673204\n",
      "0.261437908496732\n"
     ]
    }
   ],
   "source": [
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_ts, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity\n",
    "sensitivity = TP / float(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_ts, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Specificity\n",
    "specificity = TN / (TN + FP)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False positive rate (alfa)\n",
    "false_positive_rate = FP / float(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.273972602739726\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(false_positive_rate)\n",
    "print(1 - (specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "#False negative rate (beta)\n",
    "false_negative_rate = FN / float(TP+FN)\n",
    "print(false_negative_rate)\n",
    "print(1 - (sensitivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "precision = TP / float(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(metrics.precision_score(y_ts, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "#PPV\n",
    "positive_pred_value = TP / float(TP + FP)\n",
    "print(positive_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726027397260274\n"
     ]
    }
   ],
   "source": [
    "#NPV\n",
    "negative_pred_value = TN / float(TN + FN)\n",
    "print(negative_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8174657534246575\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "auc = metrics.roc_auc_score(y_ts, y_pred_prob)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:   46.0s finished\n",
      "C:\\Users\\steve\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:   36.2s finished\n",
      "C:\\Users\\steve\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Cross-validated AUC\n",
    "cv_auc = cross_val_score(rf, x, y, cv=2, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Print all metrics to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classification error = ', 0.26143790849673204)\n",
      "('Sensitivity = ', 0.75)\n",
      "('Specificity = ', 0)\n",
      "('False positive rate = ', 0.273972602739726)\n",
      "('False negative rate = ', 0.25)\n",
      "('Precision = ', 0.75)\n",
      "('PPV = ', 0.75)\n",
      "('NPV = ', 0.726027397260274)\n",
      "('AUC = ', 0.8174657534246575)\n",
      "('AUC mean 5-fold = ', 0.6369548532112606)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification error = \", classification_error)\n",
    "print(\"Sensitivity = \", sensitivity)\n",
    "print(\"Specificity = \", specificity)\n",
    "print(\"False positive rate = \", false_positive_rate)\n",
    "print(\"False negative rate = \", false_negative_rate)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"PPV = \", positive_pred_value)\n",
    "print(\"NPV = \", negative_pred_value)\n",
    "print(\"AUC = \", metrics.roc_auc_score(y_ts, y_pred_prob))\n",
    "print(\"AUC mean 5-fold = \", cv_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar graph with metrics\n",
    "sns.set_style(\"whitegrid\")\n",
    "stats = [accuracy, mcc, kappa, sensitivity, specificity, positive_pred_value, negative_pred_value, auc]\n",
    "labels = [\"Acc\", \"MCC\", \"Kappa\", \"Se\", \"Sp\", \"PPV\", \"NPV\", \"AUC\"]\n",
    "report = sns.barplot(x=labels, y=stats)\n",
    "plt.savefig('report_rf_morgan.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting calculated metrics into a pandas dataframe\n",
    "metrics = DataFrame({'Accuracy': accuracy, 'MCC': mcc, 'Kappa': kappa, \n",
    "                     'Accuracy_DA': accuracy_da, 'MCC_DA': mcc_da, 'Kappa_da': kappa_da, \n",
    "                     \"Classification error\": classification_error, \"Sensitivity\": sensitivity,\n",
    "                    \"Specificity\": specificity, \"False positive rate\": false_positive_rate,\n",
    "                    \"False negative rate\": false_negative_rate, \"Precision\": precision, \"PPV\": positive_pred_value,\n",
    "                    \"NPV\": negative_pred_value, 'AUC': auc, 'Cv_AUC': cv_auc, 'Coverage': coverage, \n",
    "                     'Coverage_DA': coverage_da}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        AUC  Accuracy  Accuracy_DA  Classification error  Coverage  \\\n",
      "0  0.817466  0.738562     0.885714              0.261438         0   \n",
      "\n",
      "   Coverage_DA    Cv_AUC  False negative rate  False positive rate     Kappa  \\\n",
      "0            0  0.636955                 0.25             0.273973  0.476027   \n",
      "\n",
      "   Kappa_da       MCC    MCC_DA       NPV   PPV  Precision  Sensitivity  \\\n",
      "0  0.755459  0.476027  0.756874  0.726027  0.75       0.75         0.75   \n",
      "\n",
      "   Specificity  \n",
      "0            0  \n"
     ]
    }
   ],
   "source": [
    "# Print the dataframe\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframe as excel file\n",
    "metrics.to_excel(\"C:/Users/steve/Documents/Datasets/dermal/metrics_Morgan_Rf.xlsx\", sheet_name= \"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
