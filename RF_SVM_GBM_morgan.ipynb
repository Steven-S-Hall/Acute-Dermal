{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary QSAR in Python - LabMol\n",
    "\n",
    "Script version 2 - 11/02/2019\n",
    "\n",
    "Developed by: Steven Hall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color='blue'> Model building with Morgan fingerprint and RF, SMV and GBM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building - Morgan_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages \n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, matthews_corrcoef, roc_curve, precision_recall_curve, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "key `Binary` exists but does not result in an integer value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0c30f088c94a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetIntProp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Binary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: key `Binary` exists but does not result in an integer value"
     ]
    }
   ],
   "source": [
    "#Reading molecules and activity (0 and 1) from SDF\n",
    "fname = \"C:/Users/steve/Documents/Datasets/dermal/Dermal_Modeling_set.sdf\"\n",
    "\n",
    "mols = []\n",
    "y = []\n",
    "for mol in Chem.SDMolSupplier(fname):\n",
    "    if mol is not None:\n",
    "        mols.append(mol)\n",
    "        y.append(mol.GetIntProp(\"Binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptors (fingerprints) and convert them into numpy array\n",
    "\n",
    "# generate binary Morgan fingerprint with radius 2\n",
    "fp = [AllChem.GetMorganFingerprintAsBitVect(m, 2,nBits=1024) for m in mols]\n",
    "\n",
    "def rdkit_numpy_convert(fp):\n",
    "    output = []\n",
    "    for f in fp:\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(f, arr)\n",
    "        output.append(arr)\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rdkit_numpy_convert(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of compounds\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a044deef9159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check wether the data set is balanced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# check wether the data set is balanced\n",
    "sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed to make all further calculations reproducible\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 20% of compounds as test set\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folds for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1\n",
      "('TRAIN:', array([115, 117, 118, 119, 125, 126, 127, 128, 131, 132, 133, 134, 135,\n",
      "       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "       162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "       175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "       188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "       201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "       240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "       253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "       266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
      "       279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "       292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "       305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317,\n",
      "       318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "       331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369,\n",
      "       370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
      "       383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "       396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
      "       409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "       422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "       435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "       448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460,\n",
      "       461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "       474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "       487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499,\n",
      "       500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512,\n",
      "       513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
      "       526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
      "       539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
      "       552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590,\n",
      "       591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603,\n",
      "       604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 120,\n",
      "       121, 122, 123, 124, 129, 130], dtype=int64))\n",
      "\n",
      "Fold_2\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 120,\n",
      "       121, 122, 123, 124, 129, 130, 229, 233, 234, 237, 243, 244, 246,\n",
      "       248, 251, 252, 253, 255, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "       266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n",
      "       279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291,\n",
      "       292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304,\n",
      "       305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317,\n",
      "       318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330,\n",
      "       331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369,\n",
      "       370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382,\n",
      "       383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "       396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
      "       409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
      "       422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
      "       435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "       448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460,\n",
      "       461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
      "       474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486,\n",
      "       487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499,\n",
      "       500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512,\n",
      "       513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
      "       526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
      "       539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
      "       552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590,\n",
      "       591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603,\n",
      "       604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([115, 117, 118, 119, 125, 126, 127, 128, 131, 132, 133, 134, 135,\n",
      "       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "       162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
      "       175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
      "       188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "       201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "       227, 228, 230, 231, 232, 235, 236, 238, 239, 240, 241, 242, 245,\n",
      "       247, 249, 250, 254, 256, 257], dtype=int64))\n",
      "\n",
      "Fold_3\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 235, 236,\n",
      "       238, 239, 240, 241, 242, 245, 247, 249, 250, 254, 256, 257, 348,\n",
      "       350, 352, 362, 364, 368, 369, 371, 374, 375, 376, 379, 380, 381,\n",
      "       382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "       395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
      "       408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
      "       421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "       434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
      "       447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
      "       460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "       473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
      "       486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
      "       551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
      "       564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576,\n",
      "       577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
      "       590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
      "       603, 604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([229, 233, 234, 237, 243, 244, 246, 248, 251, 252, 253, 255, 258,\n",
      "       259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271,\n",
      "       272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284,\n",
      "       285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "       298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310,\n",
      "       311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "       324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
      "       337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 351,\n",
      "       353, 354, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367,\n",
      "       370, 372, 373, 377, 378], dtype=int64))\n",
      "\n",
      "Fold_4\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 351, 353,\n",
      "       354, 355, 356, 357, 358, 359, 360, 361, 363, 365, 366, 367, 370,\n",
      "       372, 373, 377, 378, 485, 486, 489, 490, 491, 492, 494, 495, 496,\n",
      "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
      "       551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
      "       564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576,\n",
      "       577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
      "       590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602,\n",
      "       603, 604, 605, 606, 607, 608, 609, 610], dtype=int64))\n",
      "('TEST:', array([348, 350, 352, 362, 364, 368, 369, 371, 374, 375, 376, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "       420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "       433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "       446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "       459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471,\n",
      "       472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "       487, 488, 493, 497, 498], dtype=int64))\n",
      "\n",
      "Fold_5\n",
      "('TRAIN:', array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 487, 488, 493, 497, 498], dtype=int64))\n",
      "('TEST:', array([485, 486, 489, 490, 491, 492, 494, 495, 496, 499, 500, 501, 502,\n",
      "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
      "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
      "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
      "       542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554,\n",
      "       555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "       568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580,\n",
      "       581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593,\n",
      "       594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606,\n",
      "       607, 608, 609, 610], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# print out ids of folds\n",
    "for i, (train_index, test_index) in enumerate(cv.split(x_tr, y_tr)):\n",
    "    print(\"\\nFold_\" + str(i+1))\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale X\n",
    "#This step may be crucial for certain modeling approaches lke SVM. \n",
    "#In the case of binary fingerprints it may be less useful.\n",
    "# obtain scale object which can be further applied to scale any data to fit the training set\n",
    "scale = StandardScaler().fit(x_tr)\n",
    "x_tr = scale.transform(x_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a good idea to save it for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for optimal tuning parameters and build the model\n",
    "# create grid search dictionary\n",
    "param_grid = {\"max_features\": [x_tr.shape[1] // 10, x_tr.shape[1] // 7, x_tr.shape[1] // 5, x_tr.shape[1] // 3], \"n_estimators\": [100, 250, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': [102L, 146L, 204L, 341L], 'n_estimators': [100, 250, 500]}\n"
     ]
    }
   ],
   "source": [
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model building\n",
    "rf = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:   57.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'max_features': [102L, 146L, 204L, 341L], 'n_estimators': [100, 250, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model building\n",
    "rf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 102L, 'n_estimators': 250}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528641571194763"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74959083, 0.75286416, 0.7512275 , 0.74140753, 0.74140753,\n",
       "       0.73977087, 0.73649755, 0.74468085, 0.73813421, 0.73649755,\n",
       "       0.72667758, 0.7299509 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_features': 102L, 'n_estimators': 100},\n",
       " {'max_features': 102L, 'n_estimators': 250},\n",
       " {'max_features': 102L, 'n_estimators': 500},\n",
       " {'max_features': 146L, 'n_estimators': 100},\n",
       " {'max_features': 146L, 'n_estimators': 250},\n",
       " {'max_features': 146L, 'n_estimators': 500},\n",
       " {'max_features': 204L, 'n_estimators': 100},\n",
       " {'max_features': 204L, 'n_estimators': 250},\n",
       " {'max_features': 204L, 'n_estimators': 500},\n",
       " {'max_features': 341L, 'n_estimators': 100},\n",
       " {'max_features': 341L, 'n_estimators': 250},\n",
       " {'max_features': 341L, 'n_estimators': 500}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/steve/rf_clf.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save model - pkl file\n",
    "tuple_objects = (rf, x_tr, y_tr)\n",
    "\n",
    "joblib.dump(rf.best_estimator_, \"C:/Users/steve/rf_clf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test set compounds\n",
    "# load scale if necessary\n",
    "scale = joblib.load(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale descriptors of the test set compounds\n",
    "x_ts = scale.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Outcome class\n",
    "pred_rf = rf.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics - Morgan-RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate statistics for test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "accuracy = accuracy_score(y_ts, pred_rf)\n",
    "mcc = matthews_corrcoef(y_ts, pred_rf)\n",
    "kappa = cohen_kappa_score(y_ts, pred_rf)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "print(\"MCC = \", mcc)\n",
    "print(\"Kappa = \", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA estimation\n",
    "# if the model includes several ones like RF models or consensus models (or for probabilistic models)\n",
    "# we can calculate consistency of predictions amongs those models and use it for estimation of applicability domain\n",
    "#just remove the hashtag to execute\n",
    "pred_prob_rf = rf.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probablity\n",
    "pred_prob_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup threshold\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc maximum predicted probability for each row (compound) and compare to the threshold\n",
    "da = np.amax(pred_prob_rf, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc coverage\n",
    "coverage = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "accuracy_da = accuracy_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "mcc_da = matthews_corrcoef(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "kappa_da = cohen_kappa_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "coverage_da = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print statistics (da)\n",
    "print(\"Accuracy_DA = \", accuracy_da)\n",
    "print(\"MCC_DA = \", mcc_da)\n",
    "print(\"Kappa_DA = \", kappa_da)\n",
    "print(\"Coverage_DA = \", coverage_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "#ROC curve\n",
    "\n",
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "# we pass y_test and y_pred_prob\n",
    "# we do not use y_pred_class, because it will give incorrect results without generating an error\n",
    "# roc_curve returns 3 objects fpr, tpr, thresholds\n",
    "# fpr: false positive rate\n",
    "# tpr: true positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the predicted probabilities for class 1\n",
    "y_pred_prob = rf.predict_proba(x_ts)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_ts, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for malaria')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#Model evaluation - confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_ts, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification error or misclassification rate\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_ts, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity\n",
    "sensitivity = TP / float(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_ts, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specificity\n",
    "specificity = TN / (TN + FP)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False positive rate (alfa)\n",
    "false_positive_rate = FP / float(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(false_positive_rate)\n",
    "print(1 - (specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False negative rate (beta)\n",
    "false_negative_rate = FN / float(TP+FN)\n",
    "print(false_negative_rate)\n",
    "print(1 - (sensitivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "precision = TP / float(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision)\n",
    "print(metrics.precision_score(y_ts, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPV\n",
    "positive_pred_value = TP / float(TP + FP)\n",
    "print(positive_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPV\n",
    "negative_pred_value = TN / float(TN + FN)\n",
    "print(negative_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "auc = metrics.roc_auc_score(y_ts, y_pred_prob)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-validated AUC\n",
    "cv_auc = cross_val_score(rf, x, y, cv=2, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Print all metrics to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification error = \", classification_error)\n",
    "print(\"Sensitivity = \", sensitivity)\n",
    "print(\"Specificity = \", specificity)\n",
    "print(\"False positive rate = \", false_positive_rate)\n",
    "print(\"False negative rate = \", false_negative_rate)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"PPV = \", positive_pred_value)\n",
    "print(\"NPV = \", negative_pred_value)\n",
    "print(\"AUC = \", metrics.roc_auc_score(y_ts, y_pred_prob))\n",
    "print(\"AUC mean 5-fold = \", cv_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph with metrics\n",
    "sns.set_style(\"whitegrid\")\n",
    "stats = [accuracy, mcc, kappa, sensitivity, specificity, positive_pred_value, negative_pred_value, auc]\n",
    "labels = [\"Acc\", \"MCC\", \"Kappa\", \"Se\", \"Sp\", \"PPV\", \"NPV\", \"AUC\"]\n",
    "report = sns.barplot(x=labels, y=stats)\n",
    "plt.savefig('report_rf_morgan.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting calculated metrics into a pandas dataframe\n",
    "metrics = DataFrame({'Accuracy': accuracy, 'MCC': mcc, 'Kappa': kappa, \n",
    "                     'Accuracy_DA': accuracy_da, 'MCC_DA': mcc_da, 'Kappa_da': kappa_da, \n",
    "                     \"Classification error\": classification_error, \"Sensitivity\": sensitivity,\n",
    "                    \"Specificity\": specificity, \"False positive rate\": false_positive_rate,\n",
    "                    \"False negative rate\": false_negative_rate, \"Precision\": precision, \"PPV\": positive_pred_value,\n",
    "                    \"NPV\": negative_pred_value, 'AUC': auc, 'Cv_AUC': cv_auc, 'Coverage': coverage, \n",
    "                     'Coverage_DA': coverage_da}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataframe\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframe as excel file\n",
    "metrics.to_excel(\"C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/metrics_Morgan_Rf.xlsx\", sheet_name= \"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building - Morgan_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "param_grid = {\"C\": [10 ** i for i in range(0, 5)],\n",
    "              \"gamma\": [10 ** i for i in range(-6, 0)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model building\n",
    "svm = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model building\n",
    "svm.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(svm, \"C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/malaria_python_svm_morgan.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict Outcome class\n",
    "pred_svm = svm.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics - Morgan_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "accuracy = accuracy_score(y_ts, pred_svm)\n",
    "mcc = matthews_corrcoef(y_ts, pred_svm)\n",
    "kappa = cohen_kappa_score(y_ts, pred_svm)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "print(\"MCC = \", mcc)\n",
    "print(\"Kappa = \", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate applicability domain and calc stat\n",
    "pred_prob = svm.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc coverage\n",
    "coverage = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "accuracy_da = accuracy_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "mcc_da = matthews_corrcoef(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "kappa_da = cohen_kappa_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "coverage_da = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print statistics (da)\n",
    "print(\"Accuracy_DA = \", accuracy_da)\n",
    "print(\"MCC_DA = \", mcc_da)\n",
    "print(\"Kappa_DA = \", kappa_da)\n",
    "print(\"Coverage_DA = \", coverage_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "#ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the predicted probabilities for class 1\n",
    "y_pred_prob = svm.predict_proba(x_ts)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_ts, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for malaria')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_ts, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification accuracy - use float to perform true division, not integer division\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_ts, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification error or misclassification rate\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_ts, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity\n",
    "sensitivity = TP / float(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_ts, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specificity\n",
    "specificity = TN / (TN + FP)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False positive rate (alfa)\n",
    "false_positive_rate = FP / float(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(false_positive_rate)\n",
    "print(1 - (specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False negative rate (beta)\n",
    "false_negative_rate = FN / float(TP+FN)\n",
    "print(false_negative_rate)\n",
    "print(1 - (sensitivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "precision = TP / float(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision)\n",
    "print(metrics.precision_score(y_ts, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPV\n",
    "positive_pred_value = TP / float(TP + FP)\n",
    "print(positive_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPV\n",
    "negative_pred_value = TN / float(TN + FN)\n",
    "print(negative_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "auc = metrics.roc_auc_score(y_ts, y_pred_prob)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated AUC\n",
    "cv_auc = cross_val_score(svm, x, y, cv=2, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Print all metrics to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification error = \", classification_error)\n",
    "print(\"Sensitivity = \", sensitivity)\n",
    "print(\"Specificity = \", specificity)\n",
    "print(\"False positive rate = \", false_positive_rate)\n",
    "print(\"False negative rate = \", false_negative_rate)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"PPV = \", positive_pred_value)\n",
    "print(\"NPV = \", negative_pred_value)\n",
    "print(\"AUC = \", metrics.roc_auc_score(y_ts, y_pred_prob))\n",
    "print(\"AUC mean 5-fold = \", cv_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph with metrics\n",
    "sns.set_style(\"whitegrid\")\n",
    "stats = [accuracy, mcc, kappa, sensitivity, specificity, positive_pred_value, negative_pred_value, auc]\n",
    "labels = [\"Acc\", \"MCC\", \"Kappa\", \"Se\", \"Sp\", \"PPV\", \"NPV\", \"AUC\"]\n",
    "report = sns.barplot(x=labels, y=stats)\n",
    "plt.savefig('report_svm_morgan.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting calculated metrics into a pandas dataframe\n",
    "metrics = DataFrame({'Accuracy': accuracy, 'MCC': mcc, 'Kappa': kappa,\n",
    "                     'Accuracy_DA': accuracy_da, 'MCC_DA': mcc_da, 'Kappa_da': kappa_da,\n",
    "                     \"Classification error\": classification_error, \"Sensitivity\": sensitivity,\n",
    "                    \"Specificity\": specificity, \"False positive rate\": false_positive_rate,\n",
    "                    \"False negative rate\": false_negative_rate, \"Precision\": precision, \"PPV\": positive_pred_value,\n",
    "                    \"NPV\": negative_pred_value, 'AUC': auc, 'Cv_AUC': cv_auc, 'Coverage': coverage,\n",
    "                     'Coverage_DA': coverage_da}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataframe\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframe as excel file\n",
    "metrics.to_excel(\"C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/metrics_Morgan_SVM.xlsx\", sheet_name= \"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building - Morgan_GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [100, 200, 300, 400, 500]}\n",
    "gbm = GridSearchCV(GradientBoostingClassifier(subsample=0.5, max_features=0.5), \n",
    "                   param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model building\n",
    "gbm.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gbm = gbm.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model - pkl file\n",
    "joblib.dump(gbm, \"C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/malaria_python_gbm_morgan.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics - Morgan_GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "accuracy = accuracy_score(y_ts, pred_gbm)\n",
    "mcc = matthews_corrcoef(y_ts, pred_gbm)\n",
    "kappa = cohen_kappa_score(y_ts, pred_gbm)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "print(\"MCC = \", mcc)\n",
    "print(\"Kappa = \", kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate applicability domain and calc stat\n",
    "pred_prob = gbm.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc coverage\n",
    "coverage = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "accuracy_da = accuracy_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "mcc_da = matthews_corrcoef(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "kappa_da = cohen_kappa_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc statistics (da)\n",
    "coverage_da = sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print statistics (da)\n",
    "print(\"Accuracy_DA = \", accuracy_da)\n",
    "print(\"MCC_DA = \", mcc_da)\n",
    "print(\"Kappa_DA = \", kappa_da)\n",
    "print(\"Coverage_DA = \", coverage_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "#ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the predicted probabilities for class 1\n",
    "y_pred_prob = gbm.predict_proba(x_ts)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_ts, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for malaria')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_ts, pred_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification accuracy - use float to perform true division, not integer division\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_ts, pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification error or misclassification rate\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_ts, pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity\n",
    "sensitivity = TP / float(FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_ts, pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specificity\n",
    "specificity = TN / (TN + FP)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False positive rate (alfa)\n",
    "false_positive_rate = FP / float(TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(false_positive_rate)\n",
    "print(1 - (specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False negative rate (beta)\n",
    "false_negative_rate = FN / float(TP+FN)\n",
    "print(false_negative_rate)\n",
    "print(1 - (sensitivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "precision = TP / float(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision)\n",
    "print(metrics.precision_score(y_ts, pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPV\n",
    "positive_pred_value = TP / float(TP + FP)\n",
    "print(positive_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPV\n",
    "negative_pred_value = TN / float(TN + FN)\n",
    "print(negative_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "auc = metrics.roc_auc_score(y_ts, y_pred_prob)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated AUC\n",
    "cv_auc = cross_val_score(gbm, x, y, cv=2, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Print all metrics to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification error = \", classification_error)\n",
    "print(\"Sensitivity = \", sensitivity)\n",
    "print(\"Specificity = \", specificity)\n",
    "print(\"False positive rate = \", false_positive_rate)\n",
    "print(\"False negative rate = \", false_negative_rate)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"PPV = \", positive_pred_value)\n",
    "print(\"NPV = \", negative_pred_value)\n",
    "print(\"AUC = \", metrics.roc_auc_score(y_ts, y_pred_prob))\n",
    "print(\"AUC mean 5-fold = \", cv_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph with metrics\n",
    "sns.set_style(\"whitegrid\")\n",
    "stats = [accuracy, mcc, kappa, sensitivity, specificity, positive_pred_value, negative_pred_value, auc]\n",
    "labels = [\"Acc\", \"MCC\", \"Kappa\", \"Se\", \"Sp\", \"PPV\", \"NPV\", \"AUC\"]\n",
    "report = sns.barplot(x=labels, y=stats)\n",
    "plt.savefig('report_gbm_morgan.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting calculated metrics into a pandas dataframe\n",
    "metrics = DataFrame({'Accuracy': accuracy, 'MCC': mcc, 'Kappa': kappa,\n",
    "                     'Accuracy_DA': accuracy_da, 'MCC_DA': mcc_da, 'Kappa_da': kappa_da,\n",
    "                     \"Classification error\": classification_error, \"Sensitivity\": sensitivity,\n",
    "                    \"Specificity\": specificity, \"False positive rate\": false_positive_rate,\n",
    "                    \"False negative rate\": false_negative_rate, \"Precision\": precision, \"PPV\": positive_pred_value,\n",
    "                    \"NPV\": negative_pred_value, 'AUC': auc, 'Cv_AUC': cv_auc, 'Coverage': coverage,\n",
    "                     'Coverage_DA': coverage_da}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataframe\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframe as excel file\n",
    "metrics.to_excel(\"C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/metrics_Morgan_GBM.xlsx\", sheet_name= \"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new molecules (virtual screening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load molecules\n",
    "kaira = \"C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/PvCK1_XPbox15select-12a-8.sdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = []\n",
    "y = []\n",
    "for mol in Chem.SDMolSupplier(kaira):\n",
    "    if mol is not None:\n",
    "        mols.append(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary Morgan fingerprint with radius 2\n",
    "fp1 = [AllChem.GetMorganFingerprintAsBitVect(m, 2) for m in mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdkit_numpy_convert(fp1):\n",
    "    output = []\n",
    "    for f in fp1:\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(f, arr)\n",
    "        output.append(arr)\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = rdkit_numpy_convert(fp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x.shape)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict new data\n",
    "m = joblib.load('C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/malaria_python_rf_morgan.pkl')\n",
    "orig_pp = m.predict_proba(x1)\n",
    "orig_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the number of predicted compounds\n",
    "print(orig_pp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results in excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array to pandas dataframe\n",
    "vs = DataFrame(orig_pp, columns=['Prob_inactive', 'Prob_active'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pandas dataframe in excel file\n",
    "vs.to_excel(\"C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/teste_results.xlsx\", sheet_name= \"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results in excel file - method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('C:/Users/tiofi/Dropbox/Python/QSAR_python/Teofilo/pvck1.xlsx')\n",
    "worksheet = workbook.add_worksheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a bold format to use to highlight cells.\n",
    "bold = workbook.add_format({'bold': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet.set_column('A:C', 20)\n",
    "worksheet.write('A1', 'Prob_active', bold)\n",
    "worksheet.write('B1', 'Prob_inactive', bold)\n",
    "worksheet.write('C1', 'Final consensus', bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start from the first cell below the headers\n",
    "row = 1\n",
    "col = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over the data and write it out row by row\n",
    "for prob_active, data in (orig_pp):\n",
    "    worksheet.write(row, col,  data)\n",
    "    worksheet.write(row, col + 1, 1-data)\n",
    "    worksheet.write_array_formula('C2:C2', '{IF(A2:A2 >= 0.8, \"Virtual hit\", \"Inactive\")}') #falta melhorar isso aqui - contar colunas automaticamente\n",
    "    row += 1                                                                               #escrever os smiles correspondentes tb, ou a estrutura 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
